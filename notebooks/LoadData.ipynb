{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9f617b-e1bd-4dbc-bc4b-91b6430c3907",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Setup Data Loading Job\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514c40f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import hashlib\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F, DataFrame\n",
    "from datetime import datetime, UTC\n",
    "from delta.pip_utils import configure_spark_with_delta_pip\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Define Job Parameters\n",
    "# ----------------------------------------\n",
    "DAG_ID = \"Load CRM Data\"\n",
    "JOB_DATE = f\"{datetime.now(UTC):%Y-%m-%d}\"\n",
    "JOB_NAME = f\"{DAG_ID} {JOB_DATE}\"\n",
    "DELTA_LAKE = \"/s3-datalake/lakehouse\"\n",
    "\n",
    "source_customer_data = \"/s3-datalake/source/customer_data.parquet\"\n",
    "source_sale_data = \"/s3-datalake/source/sales_data.csv\"\n",
    "\n",
    "# Setup Logging\n",
    "# ----------------------------------------\n",
    "log.basicConfig(level=log.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bf4481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/prj/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /root/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /root/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a26627e9-80fd-4ac3-8807-505abdce7f49;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.0 in central\n",
      "\tfound io.delta#delta-storage;4.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      ":: resolution report :: resolve 126ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a26627e9-80fd-4ac3-8807-505abdce7f49\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "25/07/21 04:50:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2025-07-21 04:50:10,944 - INFO - Started session `Load CRM Data 2025-07-21`\n"
     ]
    }
   ],
   "source": [
    "# 2. Create SparkSession with Delta Config\n",
    "# ----------------------------------------\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder.appName(JOB_NAME)\n",
    "    .master(\"spark://spark:7077\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    "    .config(\"spark.sql.warehouse.dir\", DELTA_LAKE)\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "log.info(f\"Started session `{JOB_NAME}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa6b4f2-c902-4221-9c5c-43b5bed764ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup initial SCHEMAs if required\n",
    "spark.sql(\n",
    "    f\"CREATE SCHEMA IF NOT EXISTS bronze LOCATION '{DELTA_LAKE}/bronze'\"\n",
    ").collect()\n",
    "spark.sql(\n",
    "    f\"CREATE SCHEMA IF NOT EXISTS silver LOCATION '{DELTA_LAKE}/silver'\"\n",
    ").collect()\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS gold LOCATION '{DELTA_LAKE}/gold'\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f597943",
   "metadata": {},
   "source": [
    "# Bronze Layer\n",
    "---\n",
    "This layer serves as the **raw ingestion zone**, where data is landed from external systems into our Lakehouse with **minimal transformation**. It preserves the original fidelity of the data, making it ideal for auditability and replay.\n",
    "\n",
    "My typical practice in the Bronze layer includes the following steps:\n",
    "\n",
    "1. **Ingest data from external sources**, such as:\n",
    "   - Application databases (full or incremental extracts)\n",
    "   - Change Data Capture (CDC) systems\n",
    "   - Messaging systems (e.g., Kafka, Kinesis, Pub/Sub)\n",
    "   - External APIs, SFTP, blob/cloud storage, etc.\n",
    "\n",
    "2. **Apply incremental loading logic** where applicable  \n",
    "   - For example, using `kafka_timestamp` or `offset` from Kafka topics\n",
    "\n",
    "3. **Standardize column names** to align with internal naming conventions used in the Lakehouse or Warehouse\n",
    "\n",
    "4. **Add system-level metadata** for observability and debugging:\n",
    "   - Fields like `_system`, `_source`, `_ingestion_date`, etc.\n",
    "   - These are useful for tracking data lineage and pipeline behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f042cee-8ff7-49da-b561-1e4c952af89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 04:50:14,568 - INFO - Creating managed table bronze.customer in schema bronze\n",
      "2025-07-21 04:50:21,878 - INFO - Creating managed table bronze.sale in schema bronze\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Helper Functions\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "def _add_metadata(df: DataFrame, meta: dict) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Add static metadata columns to a Spark DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input Spark DataFrame.\n",
    "        meta (dict): A dictionary of column names and their corresponding literal values.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with added metadata columns.\n",
    "    \"\"\"\n",
    "    meta_columns = {col: F.lit(val) for col, val in meta.items()}\n",
    "    df_with_meta = df.withColumns(meta_columns).withColumn(\n",
    "        \"_ingestion_timestamp\", F.current_timestamp()\n",
    "    )\n",
    "\n",
    "    return df_with_meta\n",
    "\n",
    "\n",
    "def load_data(\n",
    "    data: DataFrame, table: str, metadata: dict, schema: str = \"bronze\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Load a DataFrame into a Delta Lake bronze table, partitioned by _ingestion_date.\n",
    "    Creates the table if it does not exist; otherwise, overwrites the partition for the current ingestion date.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): The source Spark DataFrame to load.\n",
    "        table (str): The target table name (used in the path and metastore).\n",
    "        metadata (dict): Static metadata to add to the DataFrame before loading.\n",
    "    \"\"\"\n",
    "    full_table_name = f\"{schema}.{table.lower()}\"\n",
    "\n",
    "    # Add metadata\n",
    "    data_with_metadata = _add_metadata(data, metadata)\n",
    "\n",
    "    # Create table if it doesn't exist\n",
    "    if not spark.catalog.tableExists(full_table_name):\n",
    "        log.info(f\"Creating managed table {full_table_name} in schema {schema}\")\n",
    "\n",
    "        data_with_metadata.write.format(\"delta\").partitionBy(\"_job_date\").mode(\n",
    "            \"overwrite\"\n",
    "        ).saveAsTable(full_table_name)\n",
    "\n",
    "        spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS bronze.{table}\n",
    "            USING DELTA\n",
    "        \"\"\")\n",
    "    else:\n",
    "        log.info(\n",
    "            f\"Overwriting existing Delta partition for {JOB_DATE} in table {full_table_name}\"\n",
    "        )\n",
    "\n",
    "        spark.sql(f\"\"\"\n",
    "            DELETE FROM {full_table_name}\n",
    "            WHERE _job_date = '{JOB_DATE}'\n",
    "        \"\"\")\n",
    "\n",
    "        data_with_metadata.write.format(\"delta\").mode(\"append\").partitionBy(\n",
    "            \"_job_date\"\n",
    "        ).saveAsTable(full_table_name)\n",
    "\n",
    "\n",
    "# Job: Load customer_data to bronze layer\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Metadata for ingestion\n",
    "metadata_customer = {\n",
    "    \"_system\": \"CRM\",\n",
    "    \"_source\": source_customer_data,\n",
    "    \"_type\": \"Parquet\",\n",
    "    \"_job_date\": JOB_DATE,\n",
    "}\n",
    "\n",
    "# Read source data\n",
    "customer_df = spark.read.parquet(source_customer_data)\n",
    "\n",
    "# Load to Delta Lake\n",
    "load_data(data=customer_df, table=\"customer\", metadata=metadata_customer)\n",
    "\n",
    "# Job: Load sale_data to bronze layer\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Metadata for ingestion\n",
    "metadata_sale = {\n",
    "    \"_system\": \"CRM\",\n",
    "    \"_source\": source_sale_data,\n",
    "    \"_type\": \"CSV\",\n",
    "    \"_job_date\": JOB_DATE,\n",
    "}\n",
    "\n",
    "# Read source data with header, and assuming all STRING data\n",
    "sale_df = (\n",
    "    spark.read.option(\"header\", True).option(\"inferSchema\", False).csv(source_sale_data)\n",
    ")\n",
    "\n",
    "# Load to Delta Lake\n",
    "load_data(data=sale_df, table=\"sale\", metadata=metadata_sale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef179c-dff9-4df8-87ff-aa19eced9242",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Silver Layer\n",
    "---\n",
    "In this layer, we transform raw Bronze data into **cleaned, structured, and enriched datasets**, ready for modeling and analytics.\n",
    "\n",
    "My typical actions in the Silver layer include:\n",
    "\n",
    "1. Load data incrementally from the Bronze layer using `_job_date`\n",
    "   - This approach simplifies handling late-arriving data, as late `event_timestamps` are still processed\n",
    "   - More complex watermark or merge strategies can be added if needed\n",
    "\n",
    "2. Clean and deduplicate records based on business rules\n",
    "\n",
    "3. Cast fields to expected data types (e.g., `timestamp`, `int`, `boolean`) per Lakehouse standards\n",
    "\n",
    "4. Generate surrogate keys for primary entities where applicable\n",
    "\n",
    "5. Add or enrich metadata columns (e.g., `_processed_at`, flags)\n",
    "\n",
    "6. Validate schema and content to ensure Silver layer standards are met\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8caae447-cac2-4c13-acc8-747a0646b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job: Query Definitions for Silver layer\n",
    "# ---------------------------------------------\n",
    "\n",
    "sql_silver_customer = \"\"\"\n",
    "        SELECT\n",
    "            * EXCEPT(gender, payment_method, age),\n",
    "            COALESCE(payment_method, 'unknown') AS payment_method,\n",
    "            CASE\n",
    "                WHEN LOWER(gender) IN ('male', 'female')\n",
    "                    THEN lower(gender)\n",
    "                ELSE 'unknown'\n",
    "            END AS gender,\n",
    "            TRY_TO_NUMBER(age, \"999\") AS age\n",
    "        FROM bronze.customer c\n",
    "        WHERE customer_id IS NOT NULL\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "invoice_date_format = \"dd-MM-yyyy\"\n",
    "sql_silver_sale = f\"\"\"\n",
    "        WITH valid_sales AS (\n",
    "            SELECT *,\n",
    "                RANK() OVER (\n",
    "                    PARTITION BY invoice_no, customer_id\n",
    "                    ORDER BY TO_DATE(invoice_date, '{invoice_date_format}')\n",
    "                ) AS rank\n",
    "            FROM bronze.sale\n",
    "            WHERE invoice_no IS NOT NULL\n",
    "              AND customer_id IS NOT NULL\n",
    "        )\n",
    "        SELECT * EXCEPT(invoice_date, shopping_mall, price, quantity),\n",
    "            TO_DATE(invoice_date, '{invoice_date_format}') AS invoice_date,\n",
    "            LOWER(shopping_mall) AS shopping_mall,\n",
    "            CAST(price AS DOUBLE) AS price,\n",
    "            CAST(quantity AS INT) AS quantity\n",
    "        FROM valid_sales\n",
    "        WHERE rank = 1\n",
    "          AND CAST(price AS DOUBLE) > 0\n",
    "          AND CAST(quantity AS INT) > 0\n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44c634f-9786-4d55-b37b-5de5ed88025d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 04:50:26,402 - INFO - Populating silver.customer from bronze.customer\n",
      "25/07/21 04:50:27 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "2025-07-21 04:50:37,833 - INFO - Populating silver.sale from bronze.sale        \n",
      "2025-07-21 04:50:38,309 - INFO - Destination table doesn't exist yet, running initial increment\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Config Section\n",
    "# -------------------------------\n",
    "DEFAULT_LOOKBACK_DAYS = 1\n",
    "\n",
    "silver_configs = {\n",
    "    \"customer\": {\n",
    "        \"bronze_table\": \"bronze.customer\",\n",
    "        \"load_type\": \"full\",  # can also be \"scd\"\n",
    "        \"sql\": sql_silver_customer,\n",
    "        \"surrogate_key_columns\": [\"customer_id\"],\n",
    "    },\n",
    "    \"sale\": {\n",
    "        \"bronze_table\": \"bronze.sale\",\n",
    "        \"load_type\": \"incremental\",\n",
    "        \"incremental_column\": \"invoice_date\",\n",
    "        \"loopback\": 1,\n",
    "        \"sql\": sql_silver_sale,\n",
    "        \"surrogate_key_columns\": [\"invoice_no\", \"customer_id\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Helper Functions\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "def _add_surrogate_key(\n",
    "    df: DataFrame, columns: list, output_col: str = \"surrogate_key\"\n",
    ") -> DataFrame:\n",
    "    concat_expr = F.concat_ws(\"||\", *[F.col(col).cast(\"string\") for col in columns])\n",
    "    return df.withColumn(output_col, F.sha1(concat_expr))\n",
    "\n",
    "\n",
    "def _add_silver_metadata(df: DataFrame, key_columns: list) -> DataFrame:\n",
    "    return (\n",
    "        _add_surrogate_key(df, key_columns)\n",
    "        .withColumn(\"_updated_at\", F.current_timestamp())\n",
    "        .withColumn(\"_created_at\", F.current_timestamp())\n",
    "    )\n",
    "\n",
    "\n",
    "def merge_into_silver(\n",
    "    new_data: DataFrame,\n",
    "    table_name: str,\n",
    "    key_column: str = \"surrogate_key\",\n",
    "    partition_column: str = None,\n",
    ") -> None:\n",
    "    if spark.catalog.tableExists(table_name):\n",
    "        new_data.createOrReplaceTempView(\"incoming\")\n",
    "\n",
    "        set_expr = \",\\n\".join(\n",
    "            [\n",
    "                f\"{col} = s.{col}\"\n",
    "                for col in new_data.columns\n",
    "                if col not in [\"_created_at\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        spark.sql(f\"\"\"\n",
    "            MERGE INTO {table_name} AS t\n",
    "            USING incoming AS s\n",
    "            ON t.{key_column} = s.{key_column}\n",
    "            WHEN MATCHED THEN\n",
    "                UPDATE SET {set_expr}\n",
    "            WHEN NOT MATCHED THEN\n",
    "                INSERT *\n",
    "        \"\"\")\n",
    "    else:\n",
    "        writer = new_data.write.format(\"delta\").mode(\"overwrite\")\n",
    "        if partition_column and partition_column in new_data.columns:\n",
    "            writer = writer.partitionBy(partition_column)\n",
    "        writer.saveAsTable(table_name)\n",
    "\n",
    "\n",
    "# Main Processing Function\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "def process_table(table_name: str, config: dict) -> None:\n",
    "    bronze_table = config[\"bronze_table\"]\n",
    "    sql_logic = config[\"sql\"]\n",
    "    sk_cols = config[\"surrogate_key_columns\"]\n",
    "    load_type = config.get(\"load_type\", \"full\")\n",
    "    incr_col = config.get(\"incremental_column\")\n",
    "    loopback = config.get(\"loopback\", DEFAULT_LOOKBACK_DAYS)\n",
    "\n",
    "    full_table_name = f\"silver.{table_name}\"\n",
    "\n",
    "    # Custom transformation logic\n",
    "    log.info(f\"Populating {full_table_name} from {bronze_table}\")\n",
    "    transformed_df = spark.sql(sql_logic)\n",
    "\n",
    "    table_exists = spark.catalog.tableExists(full_table_name)\n",
    "\n",
    "    # Only apply incremental filter if the Silver table exists\n",
    "    if load_type == \"incremental\" and incr_col and table_exists:\n",
    "        transformed_df = transformed_df.filter(\n",
    "            F.col(incr_col) >= F.date_sub(F.current_date(), loopback)\n",
    "        )\n",
    "        log.info(\n",
    "            f\"Applying incremental filter: {incr_col} >= current_date - {loopback} days\"\n",
    "        )\n",
    "    elif load_type == \"incremental\":\n",
    "        log.info(\"Destination table doesn't exist yet, running initial increment\")\n",
    "\n",
    "    # Add metadata\n",
    "    tagged_df = _add_silver_metadata(transformed_df, sk_cols)\n",
    "\n",
    "    # Merge\n",
    "    partition_col = incr_col if load_type == \"incremental\" else None\n",
    "    merge_into_silver(\n",
    "        tagged_df,\n",
    "        full_table_name,\n",
    "        key_column=\"surrogate_key\",\n",
    "        partition_column=partition_col,\n",
    "    )\n",
    "\n",
    "\n",
    "# Run All Tables\n",
    "# -------------------------------\n",
    "\n",
    "for table_name, config in silver_configs.items():\n",
    "    process_table(table_name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c343cc-03f4-47d4-8f50-9a01537b1e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   silver| customer|      false|\n",
      "|   silver|     sale|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+-------+--------------------+-----+----------+--------------------+----+------------+----------------+------+--------+--------------------+--------------------+--------------------+\n",
      "|invoice_no|customer_id|  category|_system|             _source|_type| _job_date|_ingestion_timestamp|rank|invoice_date|   shopping_mall| price|quantity|       surrogate_key|         _updated_at|         _created_at|\n",
      "+----------+-----------+----------+-------+--------------------+-----+----------+--------------------+----+------------+----------------+------+--------+--------------------+--------------------+--------------------+\n",
      "|   I109831|    C112571|  Clothing|    CRM|/s3-datalake/sour...|  CSV|2025-07-21|2025-07-21 04:50:...|   1|  2021-01-11|       metrocity|300.08|       1|efe6782159ce986d1...|2025-07-21 04:50:...|2025-07-21 04:50:...|\n",
      "|   I118183|    C223931|Technology|    CRM|/s3-datalake/sour...|  CSV|2025-07-21|2025-07-21 04:50:...|   1|  2021-01-11|mall of istanbul|3150.0|       3|27c09831d8aa50923...|2025-07-21 04:50:...|2025-07-21 04:50:...|\n",
      "|   I120905|    C445691|      Toys|    CRM|/s3-datalake/sour...|  CSV|2025-07-21|2025-07-21 04:50:...|   1|  2021-01-11|     cevahir avm| 179.2|       5|c8f5444fa5c2a3e83...|2025-07-21 04:50:...|2025-07-21 04:50:...|\n",
      "+----------+-----------+----------+-------+--------------------+-----+----------+--------------------+----+------------+----------------+------+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in silver\").show()\n",
    "spark.sql(\"select * from silver.sale\").show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2146b8d-20ae-4379-bdec-a3832952eaff",
   "metadata": {},
   "source": [
    "# Gold Layer\n",
    "---\n",
    "\n",
    "In this layer, we create clean, analytics-ready **dimension** and **fact** tables following the **Star Schema** pattern, optimized for consumption by BI tools and data analysts.\n",
    "\n",
    "This is where raw and semi-structured data is transformed into a **semantic, consistent, and high-performance model** that enables:\n",
    "- Self-serve exploration\n",
    "- Performance benchmarking\n",
    "- Time-series trend analysis\n",
    "- Operational and strategic reporting\n",
    "\n",
    "Some usual techniques include:\n",
    "\n",
    "1. Applying slowly-changing dimension logic (type 1.5 or 2) for dimensional data  \n",
    "   - Decision depends on the level of historical info required\n",
    "2. Create FAT Table (or One Big Table) for very large event streams\n",
    "   - An OBT or fat table is a fact table that is already poplulated with data from dimension tables\n",
    "2. Include additional details from the Date dimension for better analysis of cyclical behaviour\n",
    "3. Generate analytical columns like `age_band` or `is_weekend`\n",
    "4. Include surrogate key from dimensions instead of the normal key\n",
    "5. Support Incremental Loading for Large Fact Tables\n",
    "   - Apply incremental filters to avoid full reloads  \n",
    "   - Maintain partitions (e.g., by `invoice_date`) for efficient pruning of data in analytical queries\n",
    "6. De-duplication and Consistency Enforcement\n",
    "   - Ensure data quality by enforcing unique constraints on surrogate keys  \n",
    "   - Join facts only to the current version of each dimension row\n",
    "7. Materialize Common Business Metrics\n",
    "   - Derive fields like `gross_amount`, `avg_basket_size`, `customer_tenure`, etc.  \n",
    "   - This reduces repetitive logic in dashboards or downstream aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad795ff9-4a01-4bc4-82cd-44371f33b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold layer: Dimension queries\n",
    "# ---------------------------------------------\n",
    "\n",
    "sql_dim_customer = \"\"\"\n",
    "SELECT\n",
    "    surrogate_key                      AS customer_sk,\n",
    "    customer_id,\n",
    "    gender,\n",
    "    age,\n",
    "    CASE                                -- derive age_band once\n",
    "        WHEN age < 18  THEN 'under 18'\n",
    "        WHEN age BETWEEN 18 AND 24          THEN '18‑24'\n",
    "        WHEN age BETWEEN 25 AND 34          THEN '25‑34'\n",
    "        WHEN age BETWEEN 35 AND 44          THEN '35‑44'\n",
    "        WHEN age BETWEEN 45 AND 54          THEN '45‑54'\n",
    "        WHEN age BETWEEN 55 AND 64          THEN '55‑64'\n",
    "        WHEN age >= 65 THEN '65+'\n",
    "        ELSE 'unknown'\n",
    "    END                                   AS age_band,\n",
    "    payment_method,\n",
    "    current_date()                        AS _created_at,\n",
    "    current_date()                        AS _updated_at,\n",
    "    TRUE                                   AS _is_current\n",
    "FROM silver.customer\n",
    "\"\"\"\n",
    "\n",
    "scd_dim_customer = \"\"\"\n",
    "MERGE INTO gold.dim_customer AS t\n",
    "USING (\n",
    "    SELECT *\n",
    "    FROM {source}\n",
    ") AS s\n",
    "ON  t.{key}  = s.{key} AND t._is_current  = TRUE\n",
    "WHEN MATCHED THEN UPDATE\n",
    "    SET *\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT *\n",
    "WHEN NOT MATCHED BY SOURCE THEN\n",
    "    UPDATE SET _is_current = FALSE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c734ca2-eab1-4a75-9d66-630bd0a6a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold layer: Fact table queries\n",
    "# ---------------------------------------------\n",
    "\n",
    "sql_fact_sale = \"\"\"\n",
    "SELECT\n",
    "    s.surrogate_key                                 AS sale_sk,\n",
    "    s.invoice_no,\n",
    "    COALESCE(dc.customer_sk, 'unknown')             AS customer_sk,\n",
    "    s.shopping_mall,\n",
    "    s.invoice_date,\n",
    "    s.category,\n",
    "    s.quantity,\n",
    "    s.price                                         AS unit_price,\n",
    "    s.quantity * s.price                            AS gross_amount,\n",
    "    CASE\n",
    "        WHEN price < 50 THEN 'low'\n",
    "        WHEN price BETWEEN 50 AND 199.99 THEN 'medium'\n",
    "        WHEN price BETWEEN 200 AND 999.99 THEN 'high'\n",
    "        WHEN price >= 1000 THEN 'premium'\n",
    "        ELSE 'unknown'\n",
    "    END                                             AS price_bucket,    \n",
    "    dayofweek(s.invoice_date) IN (1,7)    -- Sun=1,Sat=7\n",
    "                            AS is_weekend,\n",
    "    dayofweek(s.invoice_date)                       AS week_day,\n",
    "    dayofmonth(s.invoice_date)                      AS month_day,\n",
    "    date_trunc('week',  s.invoice_date)             AS week_start_date,\n",
    "    date_trunc('month', s.invoice_date)             AS month_start_date,\n",
    "    concat(year(s.invoice_date), '-Q', quarter(s.invoice_date))\n",
    "                                                   AS fiscal_quarter,\n",
    "    current_date()                        AS _created_at,\n",
    "    current_date()                        AS _updated_at\n",
    "FROM silver.sale        s\n",
    "LEFT JOIN gold.dim_customer   dc\n",
    "       ON  dc.customer_id = s.customer_id\n",
    "       AND dc._is_current = TRUE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3266052",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_report_sales_by_segment = \"\"\"\n",
    "SELECT\n",
    "    SHA1(CONCAT_WS('|', LOWER(dc.gender), LOWER(dc.age_band))) AS segment_sk,\n",
    "    dc.gender,\n",
    "    dc.age_band,\n",
    "\n",
    "    COUNT(DISTINCT fs.invoice_no)             AS total_invoices,\n",
    "    SUM(fs.quantity)                          AS total_quantity,\n",
    "    SUM(fs.gross_amount)                      AS total_spent,\n",
    "    AVG(fs.gross_amount)                      AS avg_order_value,\n",
    "    MAX(fs.invoice_date)                      AS last_purchase_date,\n",
    "    MIN(fs.invoice_date)                      AS first_purchase_date,\n",
    "    DATE_TRUNC('month', MAX(fs.invoice_date)) AS last_active_month,\n",
    "    DATE_TRUNC('week', MAX(fs.invoice_date))  AS last_active_week,\n",
    "\n",
    "    CURRENT_DATE()                            AS _created_at,\n",
    "    CURRENT_DATE()                            AS _updated_at\n",
    "FROM gold.fact_sale fs\n",
    "LEFT JOIN gold.dim_customer dc\n",
    "  ON fs.customer_sk = dc.customer_sk\n",
    "WHERE dc._is_current = TRUE\n",
    "GROUP BY\n",
    "    dc.gender,\n",
    "    dc.age_band\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25c5c9d4-110f-4179-806a-ef3b0e3f2aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 04:52:08,950 - INFO - Destination table doesn't exist yet, running initial increment\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "gold_layer_config = {\n",
    "    \"dimensions\": [\n",
    "        {\n",
    "            \"table_name\": \"gold.dim_customer\",\n",
    "            \"sql_query\": sql_dim_customer,\n",
    "            \"scd_query\": scd_dim_customer,\n",
    "            \"key\": \"customer_sk\",\n",
    "        },\n",
    "    ],\n",
    "    \"facts\": [\n",
    "        {\n",
    "            \"table_name\": \"gold.fact_sale\",\n",
    "            \"sql_query\": sql_fact_sale,\n",
    "            \"partition_column\": \"invoice_date\",\n",
    "            \"incremental_column\": \"invoice_date\",\n",
    "            \"lookback_days\": 1,\n",
    "        },\n",
    "    ],\n",
    "    \"reports\": [\n",
    "        {\n",
    "            \"table_name\": \"gold.report_sales_by_segment\",\n",
    "            \"sql_query\": sql_report_sales_by_segment,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "def load_dim_table(table_name: str, sql_query: str, scd_query: str, key: str) -> None:\n",
    "    \"\"\"\n",
    "    Loads a dimension table, optionally apply SCD logic if it exists, otherwise creates it.\n",
    "\n",
    "    Args:\n",
    "        table_name (str): Name of the dimension table in metastore.\n",
    "        sql_query (str): SQL to select the latest dim version from Silver.\n",
    "        scd_query (str): SQL to apply type 1.5 or 2 SCD logic.\n",
    "        key (str): Join key used in the MERGE condition.\n",
    "    \"\"\"\n",
    "    staged_df = spark.sql(sql_query)\n",
    "    if spark.catalog.tableExists(table_name):\n",
    "        stage_name = table_name.split(\".\")[-1] + \"_staged\"\n",
    "        staged_df.createOrReplaceTempView(stage_name)\n",
    "        spark.sql(scd_query.format(source=stage_name, key=key))\n",
    "    else:\n",
    "        staged_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "\n",
    "def load_fact_table(\n",
    "    table_name: str,\n",
    "    sql_query: str,\n",
    "    partition_column: str = None,\n",
    "    incremental_column: str = None,\n",
    "    lookback_days: int = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Loads a fact table. Supports incremental load and optional partitioning.\n",
    "\n",
    "    Args:\n",
    "        table_name (str): Name of the fact table in metastore.\n",
    "        sql_query (str): SQL to select fact data from Silver layer.\n",
    "        partition_column (str, optional): Column to partition the fact table by.\n",
    "        incremental_column (str, optional): Column to filter for incremental load.\n",
    "        lookback_days (int): How far back to look for late data.\n",
    "    \"\"\"\n",
    "    table_exists = spark.catalog.tableExists(table_name)\n",
    "    df = spark.sql(sql_query)\n",
    "\n",
    "    if incremental_column and incremental_column in df.columns and table_exists:\n",
    "        log.info(\n",
    "            f\"Applying incremental filter: {incremental_column} >= current_date - {lookback_days} days\"\n",
    "        )\n",
    "        df = df.filter(\n",
    "            F.col(incremental_column) >= F.date_sub(F.current_date(), lookback_days)\n",
    "        )\n",
    "    elif incremental_column and not table_exists:\n",
    "        log.info(\"Destination table doesn't exist yet, running initial increment\")\n",
    "\n",
    "    writer = df.write.format(\"delta\").mode(\"append\")\n",
    "\n",
    "    if partition_column and partition_column in df.columns:\n",
    "        writer = writer.partitionBy(partition_column)\n",
    "\n",
    "    writer.saveAsTable(table_name)\n",
    "\n",
    "\n",
    "# Load dimensions\n",
    "for dim in gold_layer_config[\"dimensions\"]:\n",
    "    load_dim_table(\n",
    "        table_name=dim[\"table_name\"],\n",
    "        sql_query=dim[\"sql_query\"],\n",
    "        scd_query=dim[\"scd_query\"],\n",
    "        key=dim[\"key\"],\n",
    "    )\n",
    "\n",
    "# Load facts\n",
    "for fact in gold_layer_config[\"facts\"]:\n",
    "    load_fact_table(\n",
    "        table_name=fact[\"table_name\"],\n",
    "        sql_query=fact[\"sql_query\"],\n",
    "        partition_column=fact.get(\"partition_column\"),\n",
    "        incremental_column=fact.get(\"incremental_column\"),\n",
    "        lookback_days=fact.get(\"lookback_days\", 1),\n",
    "    )\n",
    "\n",
    "\n",
    "# Load aggregated reports\n",
    "for fact in gold_layer_config[\"reports\"]:\n",
    "    load_fact_table(\n",
    "        table_name=fact[\"table_name\"],\n",
    "        sql_query=fact[\"sql_query\"],\n",
    "        partition_column=fact.get(\"partition_column\"),\n",
    "        incremental_column=fact.get(\"incremental_column\"),\n",
    "        lookback_days=fact.get(\"lookback_days\", 1),\n",
    "    )\n",
    "\n",
    "# Load aggregated reports\n",
    "for report in gold_layer_config[\"reports\"]:\n",
    "    load_fact_table(\n",
    "        table_name=report[\"table_name\"],\n",
    "        sql_query=report[\"sql_query\"],\n",
    "        partition_column=report.get(\"partition_column\"),\n",
    "        incremental_column=report.get(\"incremental_column\"),\n",
    "        lookback_days=report.get(\"lookback_days\", 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae8d629-b11f-4ff6-88eb-b6d28bb0ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   bronze| customer|      false|\n",
      "|   bronze|     sale|      false|\n",
      "+---------+---------+-----------+\n",
      "\n",
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   silver| customer|      false|\n",
      "|   silver|     sale|      false|\n",
      "+---------+---------+-----------+\n",
      "\n",
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|     gold|        dim_customer|      false|\n",
      "|     gold|           fact_sale|      false|\n",
      "|     gold|report_sales_by_s...|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review all created tables\n",
    "# ---------------------------------------------\n",
    "\n",
    "spark.sql(\"SHOW TABLES IN bronze\").show()\n",
    "spark.sql(\"SHOW TABLES IN silver\").show()\n",
    "spark.sql(\"SHOW TABLES IN gold\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da0dace-19bf-4afc-a842-817af6a82e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## gold.report_sales_by_segment\n",
      "root\n",
      " |-- segment_sk: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age_band: string (nullable = true)\n",
      " |-- total_invoices: long (nullable = true)\n",
      " |-- total_quantity: long (nullable = true)\n",
      " |-- total_spent: double (nullable = true)\n",
      " |-- avg_order_value: double (nullable = true)\n",
      " |-- last_purchase_date: date (nullable = true)\n",
      " |-- first_purchase_date: date (nullable = true)\n",
      " |-- last_active_month: timestamp (nullable = true)\n",
      " |-- last_active_week: timestamp (nullable = true)\n",
      " |-- _created_at: date (nullable = true)\n",
      " |-- _updated_at: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_sk</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_band</th>\n",
       "      <th>total_invoices</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>avg_order_value</th>\n",
       "      <th>last_purchase_date</th>\n",
       "      <th>first_purchase_date</th>\n",
       "      <th>last_active_month</th>\n",
       "      <th>last_active_week</th>\n",
       "      <th>_created_at</th>\n",
       "      <th>_updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d1ce738adbb27155293bfac1bdfc62fef4d11d0</td>\n",
       "      <td>female</td>\n",
       "      <td>25‑34</td>\n",
       "      <td>11456</td>\n",
       "      <td>34400</td>\n",
       "      <td>28499398.29</td>\n",
       "      <td>2487.726806</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bf16c9b01c02ac268011e76b6e3822e40c58ecb0</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>70</td>\n",
       "      <td>204</td>\n",
       "      <td>134828.85</td>\n",
       "      <td>1926.126429</td>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69258257c40aebafa6ef717543de1fdc6bf322df</td>\n",
       "      <td>male</td>\n",
       "      <td>65+</td>\n",
       "      <td>3785</td>\n",
       "      <td>11387</td>\n",
       "      <td>9906508.43</td>\n",
       "      <td>2617.307379</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35b57c7ed736c4fb710049bea5021e2827436fa0</td>\n",
       "      <td>male</td>\n",
       "      <td>18‑24</td>\n",
       "      <td>5553</td>\n",
       "      <td>16474</td>\n",
       "      <td>13155744.07</td>\n",
       "      <td>2369.123730</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>656299a98b08addaf363f562d3aaf6640da45b89</td>\n",
       "      <td>female</td>\n",
       "      <td>45‑54</td>\n",
       "      <td>11348</td>\n",
       "      <td>33856</td>\n",
       "      <td>28616962.38</td>\n",
       "      <td>2521.762635</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d9843ac7a72c928dec57c1d777e0aed62d80fafc</td>\n",
       "      <td>female</td>\n",
       "      <td>35‑44</td>\n",
       "      <td>11676</td>\n",
       "      <td>35133</td>\n",
       "      <td>29772859.25</td>\n",
       "      <td>2549.919429</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264a9f1947363cce5126f03a17aa1bf0bfb8c8a4</td>\n",
       "      <td>female</td>\n",
       "      <td>18‑24</td>\n",
       "      <td>7931</td>\n",
       "      <td>24013</td>\n",
       "      <td>20275196.16</td>\n",
       "      <td>2556.448892</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7a985e241a7b653fe3c2320855c2084ad7911768</td>\n",
       "      <td>male</td>\n",
       "      <td>25‑34</td>\n",
       "      <td>7597</td>\n",
       "      <td>22705</td>\n",
       "      <td>19233668.29</td>\n",
       "      <td>2531.745201</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f26296b150ab62e8eb602d1c99bc117c6e3434b3</td>\n",
       "      <td>female</td>\n",
       "      <td>65+</td>\n",
       "      <td>5625</td>\n",
       "      <td>16958</td>\n",
       "      <td>13972109.14</td>\n",
       "      <td>2483.930514</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02f5f04b2fdd266d27c2636306a508c821f48345</td>\n",
       "      <td>male</td>\n",
       "      <td>35‑44</td>\n",
       "      <td>7703</td>\n",
       "      <td>23272</td>\n",
       "      <td>20254176.83</td>\n",
       "      <td>2629.388138</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 segment_sk  gender age_band  total_invoices  \\\n",
       "0  1d1ce738adbb27155293bfac1bdfc62fef4d11d0  female    25‑34           11456   \n",
       "1  bf16c9b01c02ac268011e76b6e3822e40c58ecb0  female  unknown              70   \n",
       "2  69258257c40aebafa6ef717543de1fdc6bf322df    male      65+            3785   \n",
       "3  35b57c7ed736c4fb710049bea5021e2827436fa0    male    18‑24            5553   \n",
       "4  656299a98b08addaf363f562d3aaf6640da45b89  female    45‑54           11348   \n",
       "5  d9843ac7a72c928dec57c1d777e0aed62d80fafc  female    35‑44           11676   \n",
       "6  264a9f1947363cce5126f03a17aa1bf0bfb8c8a4  female    18‑24            7931   \n",
       "7  7a985e241a7b653fe3c2320855c2084ad7911768    male    25‑34            7597   \n",
       "8  f26296b150ab62e8eb602d1c99bc117c6e3434b3  female      65+            5625   \n",
       "9  02f5f04b2fdd266d27c2636306a508c821f48345    male    35‑44            7703   \n",
       "\n",
       "   total_quantity  total_spent  avg_order_value last_purchase_date  \\\n",
       "0           34400  28499398.29      2487.726806         2023-03-08   \n",
       "1             204    134828.85      1926.126429         2023-02-20   \n",
       "2           11387   9906508.43      2617.307379         2023-03-08   \n",
       "3           16474  13155744.07      2369.123730         2023-03-08   \n",
       "4           33856  28616962.38      2521.762635         2023-03-08   \n",
       "5           35133  29772859.25      2549.919429         2023-03-08   \n",
       "6           24013  20275196.16      2556.448892         2023-03-08   \n",
       "7           22705  19233668.29      2531.745201         2023-03-08   \n",
       "8           16958  13972109.14      2483.930514         2023-03-08   \n",
       "9           23272  20254176.83      2629.388138         2023-03-08   \n",
       "\n",
       "  first_purchase_date last_active_month last_active_week _created_at  \\\n",
       "0          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "1          2021-01-14        2023-02-01       2023-02-20  2025-07-21   \n",
       "2          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "3          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "4          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "5          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "6          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "7          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "8          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "9          2021-01-01        2023-03-01       2023-03-06  2025-07-21   \n",
       "\n",
       "  _updated_at  \n",
       "0  2025-07-21  \n",
       "1  2025-07-21  \n",
       "2  2025-07-21  \n",
       "3  2025-07-21  \n",
       "4  2025-07-21  \n",
       "5  2025-07-21  \n",
       "6  2025-07-21  \n",
       "7  2025-07-21  \n",
       "8  2025-07-21  \n",
       "9  2025-07-21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## gold.fact_sale\n",
      "root\n",
      " |-- sale_sk: string (nullable = true)\n",
      " |-- invoice_no: string (nullable = true)\n",
      " |-- customer_sk: string (nullable = true)\n",
      " |-- shopping_mall: string (nullable = true)\n",
      " |-- invoice_date: date (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- unit_price: double (nullable = true)\n",
      " |-- gross_amount: double (nullable = true)\n",
      " |-- price_bucket: string (nullable = true)\n",
      " |-- is_weekend: boolean (nullable = true)\n",
      " |-- week_day: integer (nullable = true)\n",
      " |-- month_day: integer (nullable = true)\n",
      " |-- week_start_date: timestamp (nullable = true)\n",
      " |-- month_start_date: timestamp (nullable = true)\n",
      " |-- fiscal_quarter: string (nullable = true)\n",
      " |-- _created_at: date (nullable = true)\n",
      " |-- _updated_at: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_sk</th>\n",
       "      <th>invoice_no</th>\n",
       "      <th>customer_sk</th>\n",
       "      <th>shopping_mall</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>category</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>gross_amount</th>\n",
       "      <th>price_bucket</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>week_day</th>\n",
       "      <th>month_day</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>month_start_date</th>\n",
       "      <th>fiscal_quarter</th>\n",
       "      <th>_created_at</th>\n",
       "      <th>_updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>db226f8e01503a5c23335d17ef19daaf3b9efc5e</td>\n",
       "      <td>I100231</td>\n",
       "      <td>333269ee242c2020b55a159a67c6f2f7c2aeb301</td>\n",
       "      <td>metropol avm</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1</td>\n",
       "      <td>1050.00</td>\n",
       "      <td>1050.00</td>\n",
       "      <td>premium</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd091a2263e69b835c47494a5a4b8b2a3f5c2d24</td>\n",
       "      <td>I100964</td>\n",
       "      <td>8d0a8dd8c8de2b74623e68942f817bd2ba2b6dce</td>\n",
       "      <td>mall of istanbul</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>4</td>\n",
       "      <td>162.64</td>\n",
       "      <td>650.56</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91c2954b7272b11cf362fb9225b1f38cb0d8f182</td>\n",
       "      <td>I102694</td>\n",
       "      <td>e8b4768d72bcb5df2130dfb4dd697640efaafd69</td>\n",
       "      <td>mall of istanbul</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>5</td>\n",
       "      <td>3000.85</td>\n",
       "      <td>15004.25</td>\n",
       "      <td>premium</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6f978094d08855fcfe03f00d05ac4910d3ade425</td>\n",
       "      <td>I103853</td>\n",
       "      <td>84c413e240bf86fb4ae37c81f41fbd0cd69bb7a1</td>\n",
       "      <td>emaar square mall</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>4</td>\n",
       "      <td>2400.68</td>\n",
       "      <td>9602.72</td>\n",
       "      <td>premium</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00d0f2a037c6c65b34b9640fb935bf8adacbf670</td>\n",
       "      <td>I104465</td>\n",
       "      <td>2ad82953b80c8fa23119ee72061681356ab8a849</td>\n",
       "      <td>cevahir avm</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>1</td>\n",
       "      <td>40.66</td>\n",
       "      <td>40.66</td>\n",
       "      <td>low</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4d2c8da23d2221cb82c24a797f78832700a57e61</td>\n",
       "      <td>I113088</td>\n",
       "      <td>904af6865f0fa0ea3e0098042b0999110a94aecf</td>\n",
       "      <td>metropol avm</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>5</td>\n",
       "      <td>26.15</td>\n",
       "      <td>130.75</td>\n",
       "      <td>low</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16fb86e04557ebb1ecc0373f08477c50be6a1cd4</td>\n",
       "      <td>I114725</td>\n",
       "      <td>fa6d8b20304ba21d420ed169466963b1c6ee50d1</td>\n",
       "      <td>kanyon</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Toys</td>\n",
       "      <td>5</td>\n",
       "      <td>179.20</td>\n",
       "      <td>896.00</td>\n",
       "      <td>medium</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1c06a51ac3596798a203d4b5ac5bd0ecf6af2b53</td>\n",
       "      <td>I116331</td>\n",
       "      <td>c1a5430035bb84c781871c44f74c9cdcc38e5d9d</td>\n",
       "      <td>mall of istanbul</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>2</td>\n",
       "      <td>10.46</td>\n",
       "      <td>20.92</td>\n",
       "      <td>low</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>193b26e368117c011290bf3933962c497fb00eab</td>\n",
       "      <td>I119564</td>\n",
       "      <td>40f295decfdd43c0cce1e5c9c799cc9ca77fa1eb</td>\n",
       "      <td>metrocity</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>1</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.23</td>\n",
       "      <td>low</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44874466742864bdaf66332eb46fce076db273ec</td>\n",
       "      <td>I123859</td>\n",
       "      <td>82c6d5a4b810c4d26ecc694b8a456ac6211b82ac</td>\n",
       "      <td>metropol avm</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>1</td>\n",
       "      <td>40.66</td>\n",
       "      <td>40.66</td>\n",
       "      <td>low</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sale_sk invoice_no  \\\n",
       "0  db226f8e01503a5c23335d17ef19daaf3b9efc5e    I100231   \n",
       "1  fd091a2263e69b835c47494a5a4b8b2a3f5c2d24    I100964   \n",
       "2  91c2954b7272b11cf362fb9225b1f38cb0d8f182    I102694   \n",
       "3  6f978094d08855fcfe03f00d05ac4910d3ade425    I103853   \n",
       "4  00d0f2a037c6c65b34b9640fb935bf8adacbf670    I104465   \n",
       "5  4d2c8da23d2221cb82c24a797f78832700a57e61    I113088   \n",
       "6  16fb86e04557ebb1ecc0373f08477c50be6a1cd4    I114725   \n",
       "7  1c06a51ac3596798a203d4b5ac5bd0ecf6af2b53    I116331   \n",
       "8  193b26e368117c011290bf3933962c497fb00eab    I119564   \n",
       "9  44874466742864bdaf66332eb46fce076db273ec    I123859   \n",
       "\n",
       "                                customer_sk      shopping_mall invoice_date  \\\n",
       "0  333269ee242c2020b55a159a67c6f2f7c2aeb301       metropol avm   2021-07-19   \n",
       "1  8d0a8dd8c8de2b74623e68942f817bd2ba2b6dce   mall of istanbul   2021-07-19   \n",
       "2  e8b4768d72bcb5df2130dfb4dd697640efaafd69   mall of istanbul   2021-07-19   \n",
       "3  84c413e240bf86fb4ae37c81f41fbd0cd69bb7a1  emaar square mall   2021-07-19   \n",
       "4  2ad82953b80c8fa23119ee72061681356ab8a849        cevahir avm   2021-07-19   \n",
       "5  904af6865f0fa0ea3e0098042b0999110a94aecf       metropol avm   2021-07-19   \n",
       "6  fa6d8b20304ba21d420ed169466963b1c6ee50d1             kanyon   2021-07-19   \n",
       "7  c1a5430035bb84c781871c44f74c9cdcc38e5d9d   mall of istanbul   2021-07-19   \n",
       "8  40f295decfdd43c0cce1e5c9c799cc9ca77fa1eb          metrocity   2021-07-19   \n",
       "9  82c6d5a4b810c4d26ecc694b8a456ac6211b82ac       metropol avm   2021-07-19   \n",
       "\n",
       "          category  quantity  unit_price  gross_amount price_bucket  \\\n",
       "0       Technology         1     1050.00       1050.00      premium   \n",
       "1        Cosmetics         4      162.64        650.56       medium   \n",
       "2            Shoes         5     3000.85      15004.25      premium   \n",
       "3            Shoes         4     2400.68       9602.72      premium   \n",
       "4        Cosmetics         1       40.66         40.66          low   \n",
       "5  Food & Beverage         5       26.15        130.75          low   \n",
       "6             Toys         5      179.20        896.00       medium   \n",
       "7  Food & Beverage         2       10.46         20.92          low   \n",
       "8  Food & Beverage         1        5.23          5.23          low   \n",
       "9        Cosmetics         1       40.66         40.66          low   \n",
       "\n",
       "   is_weekend  week_day  month_day week_start_date month_start_date  \\\n",
       "0       False         2         19      2021-07-19       2021-07-01   \n",
       "1       False         2         19      2021-07-19       2021-07-01   \n",
       "2       False         2         19      2021-07-19       2021-07-01   \n",
       "3       False         2         19      2021-07-19       2021-07-01   \n",
       "4       False         2         19      2021-07-19       2021-07-01   \n",
       "5       False         2         19      2021-07-19       2021-07-01   \n",
       "6       False         2         19      2021-07-19       2021-07-01   \n",
       "7       False         2         19      2021-07-19       2021-07-01   \n",
       "8       False         2         19      2021-07-19       2021-07-01   \n",
       "9       False         2         19      2021-07-19       2021-07-01   \n",
       "\n",
       "  fiscal_quarter _created_at _updated_at  \n",
       "0        2021-Q3  2025-07-21  2025-07-21  \n",
       "1        2021-Q3  2025-07-21  2025-07-21  \n",
       "2        2021-Q3  2025-07-21  2025-07-21  \n",
       "3        2021-Q3  2025-07-21  2025-07-21  \n",
       "4        2021-Q3  2025-07-21  2025-07-21  \n",
       "5        2021-Q3  2025-07-21  2025-07-21  \n",
       "6        2021-Q3  2025-07-21  2025-07-21  \n",
       "7        2021-Q3  2025-07-21  2025-07-21  \n",
       "8        2021-Q3  2025-07-21  2025-07-21  \n",
       "9        2021-Q3  2025-07-21  2025-07-21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## gold.dim_customer\n",
      "root\n",
      " |-- customer_sk: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: decimal(3,0) (nullable = true)\n",
      " |-- age_band: string (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- _created_at: date (nullable = true)\n",
      " |-- _updated_at: date (nullable = true)\n",
      " |-- _is_current: boolean (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_sk</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_band</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>_created_at</th>\n",
       "      <th>_updated_at</th>\n",
       "      <th>_is_current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8b687283db5662770fab89cb1d063f0b567500fb</td>\n",
       "      <td>C241288</td>\n",
       "      <td>female</td>\n",
       "      <td>28</td>\n",
       "      <td>25‑34</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1934f07403d2e4a74cf6d9eb60a7bff5a8b71ef2</td>\n",
       "      <td>C111565</td>\n",
       "      <td>male</td>\n",
       "      <td>21</td>\n",
       "      <td>18‑24</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390f8635c228b30217c5ffa80066782d61e3aadc</td>\n",
       "      <td>C266599</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>18‑24</td>\n",
       "      <td>Cash</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d236689e0b06e2d34261a7f7d205969bea88b544</td>\n",
       "      <td>C988172</td>\n",
       "      <td>female</td>\n",
       "      <td>66</td>\n",
       "      <td>65+</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>974c815d58acf79eac60d39dd85c32841bed2dd9</td>\n",
       "      <td>C189076</td>\n",
       "      <td>female</td>\n",
       "      <td>53</td>\n",
       "      <td>45‑54</td>\n",
       "      <td>Cash</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b151e0e3cae85ef2839cf9411d66373938556451</td>\n",
       "      <td>C657758</td>\n",
       "      <td>female</td>\n",
       "      <td>28</td>\n",
       "      <td>25‑34</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>196d8b9956165925cbe3fb5eba7ff3d792579671</td>\n",
       "      <td>C151197</td>\n",
       "      <td>female</td>\n",
       "      <td>49</td>\n",
       "      <td>45‑54</td>\n",
       "      <td>Cash</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ffec33d90f607d48c94b5077bfcb797cec5c8355</td>\n",
       "      <td>C176086</td>\n",
       "      <td>female</td>\n",
       "      <td>32</td>\n",
       "      <td>25‑34</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5336f67c010c0f429ff1edfc5078e2aa08fff476</td>\n",
       "      <td>C159642</td>\n",
       "      <td>male</td>\n",
       "      <td>69</td>\n",
       "      <td>65+</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2b94b719c381043d639d8119247354b9b63f611f</td>\n",
       "      <td>C283361</td>\n",
       "      <td>female</td>\n",
       "      <td>60</td>\n",
       "      <td>55‑64</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                customer_sk customer_id  gender age age_band  \\\n",
       "0  8b687283db5662770fab89cb1d063f0b567500fb     C241288  female  28    25‑34   \n",
       "1  1934f07403d2e4a74cf6d9eb60a7bff5a8b71ef2     C111565    male  21    18‑24   \n",
       "2  390f8635c228b30217c5ffa80066782d61e3aadc     C266599    male  20    18‑24   \n",
       "3  d236689e0b06e2d34261a7f7d205969bea88b544     C988172  female  66      65+   \n",
       "4  974c815d58acf79eac60d39dd85c32841bed2dd9     C189076  female  53    45‑54   \n",
       "5  b151e0e3cae85ef2839cf9411d66373938556451     C657758  female  28    25‑34   \n",
       "6  196d8b9956165925cbe3fb5eba7ff3d792579671     C151197  female  49    45‑54   \n",
       "7  ffec33d90f607d48c94b5077bfcb797cec5c8355     C176086  female  32    25‑34   \n",
       "8  5336f67c010c0f429ff1edfc5078e2aa08fff476     C159642    male  69      65+   \n",
       "9  2b94b719c381043d639d8119247354b9b63f611f     C283361  female  60    55‑64   \n",
       "\n",
       "  payment_method _created_at _updated_at  _is_current  \n",
       "0    Credit Card  2025-07-21  2025-07-21         True  \n",
       "1     Debit Card  2025-07-21  2025-07-21         True  \n",
       "2           Cash  2025-07-21  2025-07-21         True  \n",
       "3    Credit Card  2025-07-21  2025-07-21         True  \n",
       "4           Cash  2025-07-21  2025-07-21         True  \n",
       "5    Credit Card  2025-07-21  2025-07-21         True  \n",
       "6           Cash  2025-07-21  2025-07-21         True  \n",
       "7    Credit Card  2025-07-21  2025-07-21         True  \n",
       "8    Credit Card  2025-07-21  2025-07-21         True  \n",
       "9    Credit Card  2025-07-21  2025-07-21         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review all table data\n",
    "# ---------------------------------------------\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "report_df = spark.sql(\"SELECT * FROM gold.report_sales_by_segment\")\n",
    "print(\"## gold.report_sales_by_segment\")\n",
    "report_df.printSchema()\n",
    "display(report_df.toPandas().head(10))\n",
    "\n",
    "\n",
    "fact_df = spark.sql(\"SELECT * FROM gold.fact_sale\")\n",
    "print(\"## gold.fact_sale\")\n",
    "fact_df.printSchema()\n",
    "display(fact_df.toPandas().head(10))\n",
    "\n",
    "\n",
    "dim_df = spark.sql(\"SELECT * FROM gold.dim_customer\")\n",
    "print(\"## gold.dim_customer\")\n",
    "dim_df.printSchema()\n",
    "display(dim_df.toPandas().head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
